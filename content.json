{"posts":[{"title":"4.Iris与集成学习","text":"摘要第四次机器学习课程实验仅供参考 将数据集按7：3 的比例随机划分为训练集和验证集，随机数生成器种子为学号后三位数431，并输出训练集和验证集前10行数据； 1234567891011121314151617181920212223242526from sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitimport pandas as pd# 加载数据集data = load_iris()X = data.datay = data.target# 划分训练集和验证集（7:3比例）X_train, X_val, y_train, y_val = train_test_split( X, y, test_size=0.3, random_state=431)# 组合特征和标签，并添加列名columns = data.feature_names + [&apos;target&apos;]train_data = pd.DataFrame(X_train, columns=data.feature_names)train_data[&apos;target&apos;] = y_trainval_data = pd.DataFrame(X_val, columns=data.feature_names)val_data[&apos;target&apos;] = y_val# 输出结果print(&quot;训练集前10行数据：&quot;)print(train_data.head(10))print(&quot;\\n验证集前10行数据：&quot;)print(val_data.head(10)) &lt;font size=1&gt;训练集前10行数据： sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) \\ 0 4.7 3.2 1.6 0.2 1 6.5 3.0 5.5 1.8 2 4.9 3.1 1.5 0.1 3 5.6 3.0 4.5 1.5 4 5.0 3.4 1.5 0.2 5 5.8 2.6 4.0 1.2 6 4.9 2.4 3.3 1.0 7 4.6 3.2 1.4 0.2 8 5.7 2.6 3.5 1.0 9 5.4 3.9 1.3 0.4 target 0 0 1 2 2 0 3 1 4 0 5 1 6 1 7 0 8 1 9 0 验证集前10行数据： sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) \\ 0 5.4 3.7 1.5 0.2 1 6.7 3.3 5.7 2.5 2 5.0 2.0 3.5 1.0 3 5.1 3.5 1.4 0.3 4 4.4 3.0 1.3 0.2 5 4.7 3.2 1.3 0.2 6 6.4 2.9 4.3 1.3 7 4.4 3.2 1.3 0.2 8 5.7 3.0 4.2 1.2 9 5.1 3.3 1.7 0.5 target 0 0 1 2 2 1 3 0 4 0 5 0 6 1 7 0 8 1 9 0 在训练集上训练决策树模型，生成如下的决策树边界 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879from sklearn.tree import DecisionTreeClassifierimport numpy as npimport matplotlib.pyplot as pltfrom matplotlib.colors import ListedColormap# 设置字体为支持中文的字体plt.rcParams[&apos;font.sans-serif&apos;] = [&apos;SimHei&apos;] # 指定中文字体为黑体plt.rcParams[&apos;axes.unicode_minus&apos;] = False # 解决负号显示问题# 选择用于绘制的特征：花瓣长度（第3列）和花瓣宽度（第4列）X_train_petal = X_train[:, [2, 3]]X_val_petal = X_val[:, [2, 3]]# 训练决策树模型（使用花瓣特征）max_depth = 3tree_clf = DecisionTreeClassifier(max_depth=max_depth, random_state=431)tree_clf.fit(X_train_petal, y_train)# 生成网格数据x_min, x_max = 0, 7.2y_min, y_max = 0, 3xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))# 预测整个网格的类别Z = tree_clf.predict(np.c_[xx.ravel(), yy.ravel()])Z = Z.reshape(xx.shape)# 创建颜色映射custom_cmap = ListedColormap([&apos;#fafab0&apos;, &apos;#9898ff&apos;, &apos;#a0faa0&apos;])# 绘制决策边界plt.figure(figsize=(10, 6))plt.contourf(xx, yy, Z, alpha=0.3, cmap=custom_cmap)# 绘制训练数据点markers = (&apos;o&apos;, &apos;s&apos;, &apos;^&apos;)for idx, marker in zip(range(3), markers): plt.scatter(X_train_petal[y_train == idx, 0], X_train_petal[y_train == idx, 1], marker=marker, label=f&quot;{data.target_names[idx]} (train)&quot;)# 提取决策树阈值def get_thresholds(tree): thresholds = [] features = [] stack = [0] # 从根节点开始 while stack: node_id = stack.pop() if tree.children_left[node_id] != tree.children_right[node_id]: thresholds.append(tree.threshold[node_id]) features.append(tree.feature[node_id]) stack.append(tree.children_left[node_id]) stack.append(tree.children_right[node_id]) return thresholds, featuresthresholds, features = get_thresholds(tree_clf.tree_)# 绘制决策边界线line_styles = [&apos;-&apos;, &apos;--&apos;, &apos;:&apos;]for i, (th, feat) in enumerate(zip(thresholds, features)): if feat == 0: # 花瓣长度 plt.plot([th, th], [y_min, y_max], linestyle=line_styles[i%3], color=&apos;k&apos;, linewidth=2) elif feat == 1: # 花瓣宽度 plt.plot([x_min, x_max], [th, th], linestyle=line_styles[i%3], color=&apos;k&apos;, linewidth=2)# 添加标注和美化plt.title(f&quot;决策树(最大深度={max_depth})边界 电信2206赵连政0122209360431&quot;)plt.xlabel(&quot;Petal length (cm)&quot;)plt.ylabel(&quot;Petal width (cm)&quot;)plt.axis([x_min, x_max, y_min, y_max])plt.legend(loc=&quot;upper left&quot;)plt.grid(True, alpha=0.2)plt.show() 在训练集上训练Bagging（基学习器自选）和随机森林模型，基学习器个数为100，输出决策边界图，并分析结果差异； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475from sklearn.ensemble import BaggingClassifier, RandomForestClassifierimport matplotlib.pyplot as pltimport numpy as npfrom matplotlib.colors import ListedColormap# 设置基础参数n_estimators = 100max_depth = 3 # 保持与之前决策树相同深度random_seed = 431# 初始化模型bagging_clf = BaggingClassifier( DecisionTreeClassifier(max_depth=max_depth), n_estimators=n_estimators, random_state=random_seed)rf_clf = RandomForestClassifier( n_estimators=n_estimators, max_depth=max_depth, random_state=random_seed)# 训练模型bagging_clf.fit(X_train_petal, y_train)rf_clf.fit(X_train_petal, y_train)# 创建网格数据x_min, x_max = 0, 7.2y_min, y_max = 0, 3xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))# 定义可视化函数def plot_decision_boundary(clf, title, ax): # 预测网格 Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape) # 绘制决策边界 custom_cmap = ListedColormap([&apos;#fafab0&apos;, &apos;#9898ff&apos;, &apos;#a0faa0&apos;]) ax.contourf(xx, yy, Z, alpha=0.3, cmap=custom_cmap) ax.contour(xx, yy, Z, cmap=&quot;YlGn&quot;, alpha=0.8 ) # 绘制训练数据点 markers = (&apos;o&apos;, &apos;s&apos;, &apos;^&apos;) for idx, marker in enumerate(markers): ax.scatter(X_train_petal[y_train == idx, 0], X_train_petal[y_train == idx, 1], marker=marker, label=data.target_names[idx]) # 美化设置 ax.set_title(title) ax.set_xlabel(&quot;Petal length (cm)&quot;) ax.set_ylabel(&quot;Petal width (cm)&quot;) ax.axis([x_min, x_max, y_min, y_max]) ax.legend(loc=&quot;upper left&quot;) ax.grid(True, alpha=0.2)# 创建对比图plt.figure(figsize=(18, 6))plt.suptitle(&apos;电信2206赵连政0122209360431&apos;, fontsize=16, fontweight=&apos;bold&apos;, y=1.05)# Bagging决策边界ax1 = plt.subplot(1, 2, 1)plot_decision_boundary(bagging_clf, &quot;Bagging (100 Decision Trees)&quot;, ax1)# 随机森林决策边界ax2 = plt.subplot(1, 2, 2)plot_decision_boundary(rf_clf, &quot;随机森林 (100 Trees)&quot;, ax2)plt.tight_layout()plt.show()# 验证集准确率对比print(f&quot;Bagging验证集准确率: {bagging_clf.score(X_val_petal, y_val):.3f}&quot;)print(f&quot;随机森林验证集准确率: {rf_clf.score(X_val_petal, y_val):.3f}&quot;) Bagging验证集准确率: 0.978 随机森林验证集准确率: 0.956 分别计算决策树、Bagging（基学习器自选）和随机森林模型在Iris数据集上三分类的混淆矩阵，并对三种算法的输出结果进行比较. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 计算混淆矩阵def print_confusion_matrix(y_true, y_pred, model_name): cm = confusion_matrix(y_true, y_pred) print(f&quot;{model_name} 混淆矩阵:&quot;) print(cm) print(f&quot;{model_name} 分类报告:&quot;) print(classification_report(y_true, y_pred)) return cm# 绘制混淆矩阵def plot_confusion_matrix(cm, model_name, ax): im = ax.imshow(cm, interpolation=&apos;nearest&apos;, cmap=plt.cm.Blues) ax.set_title(f&quot;{model_name} 混淆矩阵&quot;) tick_marks = np.arange(len(data.target_names)) ax.set_xticks(tick_marks) ax.set_yticks(tick_marks) ax.set_xticklabels(data.target_names) ax.set_yticklabels(data.target_names) ax.set_xlabel(&apos;预测标签&apos;) ax.set_ylabel(&apos;真实标签&apos;) # 添加数值标签 for i in range(len(data.target_names)): for j in range(len(data.target_names)): ax.text(j, i, cm[i, j], ha=&apos;center&apos;, va=&apos;center&apos;, color=&apos;white&apos; if cm[i, j] &gt; cm.max() / 2 else &apos;black&apos;) return im# 计算并打印混淆矩阵cm_tree = print_confusion_matrix(y_val, y_pred_tree, &quot;决策树&quot;)cm_bagging = print_confusion_matrix(y_val, y_pred_bagging, &quot;Bagging&quot;)cm_rf = print_confusion_matrix(y_val, y_pred_rf, &quot;随机森林&quot;)# 绘制混淆矩阵fig = plt.figure(figsize=(18, 8))gs = gridspec.GridSpec(1, 3)ax0 = fig.add_subplot(gs[0, 0])ax1 = fig.add_subplot(gs[0, 1])ax2 = fig.add_subplot(gs[0, 2])plot_confusion_matrix(cm_tree, &quot;决策树&quot;, ax0)plot_confusion_matrix(cm_bagging, &quot;Bagging&quot;, ax1)plot_confusion_matrix(cm_rf, &quot;随机森林&quot;, ax2)# 添加水平颜色条cax = fig.add_axes([0.3, 0.15, 0.4, 0.03]) # 调整位置和大小fig.colorbar(plt.cm.ScalarMappable(cmap=plt.cm.Blues), cax=cax, orientation=&apos;horizontal&apos;)plt.tight_layout(rect=[0, 0.2, 1, 1]) # 调整布局以避免颜色条重叠plt.show() 决策树 混淆矩阵: [[19 0 0] [ 0 10 1] [ 0 1 14]] 决策树 分类报告: precision recall f1-score support 0 1.00 1.00 1.00 19 1 0.91 0.91 0.91 11 2 0.93 0.93 0.93 15 accuracy 0.96 45 macro avg 0.95 0.95 0.95 45 weighted avg 0.96 0.96 0.96 45 Bagging 混淆矩阵: [[19 0 0] [ 0 10 1] [ 0 0 15]] Bagging 分类报告: precision recall f1-score support 0 1.00 1.00 1.00 19 1 1.00 0.91 0.95 11 2 0.94 1.00 0.97 15 accuracy 0.98 45 macro avg 0.98 0.97 0.97 45 weighted avg 0.98 0.98 0.98 45 随机森林 混淆矩阵: [[19 0 0] [ 0 10 1] [ 0 1 14]] 随机森林 分类报告: precision recall f1-score support 0 1.00 1.00 1.00 19 1 0.91 0.91 0.91 11 2 0.93 0.93 0.93 15 accuracy 0.96 45 macro avg 0.95 0.95 0.95 45 weighted avg 0.96 0.96 0.96 45 C:\\Users\\86182\\AppData\\Local\\Temp\\ipykernel_11464\\1982013248.py:50: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect. plt.tight_layout(rect=[0, 0.2, 1, 1]) # 调整布局以避免颜色条重叠","link":"/2025/12/18/4-Iris%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"},{"title":"第一次实验：短时时域分析","text":"摘要语音信号处理第一次实验仅供参考 一、 实验内容概述：本次实验实验前语音数据准备以及语音实验内容两个部分。实验前语音数据准备要求录制并加载语音数据文件WHUT_10k，绘制完整波形图找出并移除前后噪声段，确保录音数据质量。语音实验内容围绕语音信号处理基础，涵盖了绘制分帧加窗图、计算语音短时能量、语音短时幅度、语音短时过零率以及计算语音短时自相关。 二、 编程思路及步骤实验前语音数据准备部分，利用Lectrue1_Demo_speech_recorder.m代码加载语音数据文件，通过绘制完整波形图找出前后噪声段，进行处理，使用代码截取无噪声段区间以获得纯净音频，并保存处理后的语音数据及对应图像。语音实验内容中的分帧加窗图绘制，先读取语音文件，确定帧长20ms和帧移50%，进行分帧操作，确保列存储。提取第 45 帧后，分别生成矩形窗和 Hamming 窗函数，对第 45 帧数据加窗处理。最后绘制原始信号与加窗后信号的对比图。计算每帧信号的平方和，得到短时能量。逐帧计算信号的绝对值之和，绘制短时幅度随时间的变化曲线。按照公式$ZCR(t)=\\frac{1}{N}\\sum_{n=0}^{N-1}\\frac{1}{2}|\\mathrm{sign}(x(t+n))-\\mathrm{sign}(x(t+n-1))|$统计每帧内信号符号变化的次数。逐帧计算信号的自相关函数，绘制短时自相关随延迟时间的变化曲线。 三、 指定内容的输出结果一、 实验前语音数据准备利用Lectrue1_Demo_speech_recorder.m文件代码录制音频“武汉理工大学”，并截取无噪声段区间，获得纯净音频。 1234567891011121314151617181920212223242526272829303132333435fs = 10000; % set sampling rater = audiorecorder(fs, 24, 1); % creat a recoreder objectrecord(r); % speak into microphone...pause(4); % set recording timestop(r); % stop recordingdata0 = getaudiodata(r); % get audio datasound(data0, fs) % listen to complete recordingplot(data0)data = data0(3706: 18181);sound(data, fs) figuret = (1:length(data))/fs;plot(t, data)sound(data, fs)xlabel(&apos;时间/ s&apos;)ylabel(&apos;振幅&apos;)axis tighttitle({&apos;电信2206 赵连政 0122209360431&apos;&apos;武汉理工大学&apos;})fileName = &apos;WHUT10K2025&apos;;saveDataDir = &apos;./data2025/&apos;;saveDataName = strcat(saveDataDir, fileName);if ~exist(saveDataDir, &apos;dir&apos;) mkdir(saveDataDir)endsave(saveDataName, &apos;data&apos;, &apos;fs&apos;) % save audio data as mat format%save(&apos;A12345&apos;)saveFigureDir = &apos;./figure2025/&apos;;if ~exist(saveFigureDir, &apos;dir&apos;) mkdir(saveFigureDir)endsaveFigureName = strcat(saveFigureDir, fileName);title(&apos;png&apos;)print(saveFigureName, &apos;-dpng&apos;)title(&apos;emf&apos;)print(saveFigureName, &apos;-dmeta&apos;) 1上述图像前后各有一段近似为0的波形，该区域即为不含语音信息的噪声。3706-18181为有效音频段，以外为噪声段。波形在-1~+1之间，幅度合适。 1上述图像前后不含噪声波形，已经截取为含有“武汉理工大学”语音信号波形，图像更加紧凑。 二、语音实验内容：首先画出Ah 第20帧时域波形图，10k采样，与实验要求给出的图像进行对比：1． 分帧加窗图：画出oh语音第45帧单帧语音时域图，同时加矩形窗和hamming窗（oh语音，第45帧） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748%% 分帧加窗对比图（oh语音第45帧）clc; clear; close all;name = &apos;赵连政&apos;;class = &apos;电信2206&apos;;id = &apos;0122209360431&apos;;% 读取语音文件（文件名为&apos;oh.wav&apos;，采样率10kHz）[y, fs] = audioread(&apos;oh.wav&apos;); frame_duration = 0.02; % 帧长20msframe_length = round(frame_duration * fs);frame_shift = frame_length/2; % 50%帧移% 分帧操作（确保列存储）frames = buffer(y, frame_length, frame_length - frame_shift, &apos;nodelay&apos;);frame45 = frames(:,45); % 提取第45帧（列向量）% 生成窗函数（列向量）rect_win = ones(size(frame45));hamm_win = hamming(length(frame45));% 加窗操作frame_rect = frame45 .* rect_win;frame_hamm = frame45 .* hamm_win;% 矩形窗对比figure(&apos;Color&apos;,&apos;white&apos;);hold on;plot(frame45, &apos;b&apos;, &apos;LineWidth&apos;, 1.2);plot(frame_rect, &apos;r&apos;, &apos;LineWidth&apos;, 1);hold off;legend(&apos;原始信号&apos;, &apos;矩形窗处理&apos;);title({[name &apos; &apos; class &apos; &apos; id] &apos;Oh语音第45帧加窗对比 (矩形窗)&apos;});xlabel(&apos;采样点&apos;); ylabel(&apos;幅度&apos;);grid on;% Hamming窗对比figure(&apos;Color&apos;,&apos;white&apos;);hold on;plot(frame45, &apos;b&apos;, &apos;LineWidth&apos;, 1.2);plot(frame_hamm, &apos;m--&apos;, &apos;LineWidth&apos;, 1);hold off;legend(&apos;原始信号&apos;, &apos;Hamming窗处理&apos;);title({[name &apos; &apos; class &apos; &apos; id] &apos;Oh语音第45帧加窗对比 (Hamming窗)&apos;});xlabel(&apos;采样点&apos;);ylabel(&apos;幅度&apos;);grid on;% 添加公共标注annotation(&apos;textbox&apos;,... [0.3 0.001 0.4 0.05],... &apos;String&apos;,[&apos;语音内容: oh语音第45帧 | 采样率: &apos; num2str(fs/1000) &apos;kHz&apos;],... &apos;FitBoxToText&apos;,&apos;on&apos;,... &apos;EdgeColor&apos;,&apos;none&apos;,... &apos;HorizontalAlignment&apos;,&apos;center&apos;); 12蓝色曲线是原始信号，粉色曲线是经过 Hamming 窗处理后的信号。对于 Hamming 窗处理后的信号，其波形在帧的起始和结束处被衰减。这是因为 Hamming 窗是一种升余弦窗，窗函数在两端趋近于 0，中间部分接近 1。在采样点 0 和 200 附近，信号幅度被明显压低，相比原始信号，其起始和结束部分的波动幅度变小。 1蓝色曲线是原始信号，红色曲线是经过矩形窗处理后的信号。矩形窗处理后的信号与原始信号在时域波形上基本一致。因为矩形窗函数在整个窗口范围内值都为 1，相当于没有对信号进行加权处理，只是简单地截取了一段信号作为一帧。 2． 语音短时能量（武汉理工大学语音） 123456789101112131415161718192021222324252627282930% 1. 加载语音文件load(&apos;WHUT10K2025.mat&apos;); % 信号变量名为&apos;data&apos;，采样率为&apos;fs&apos;% 2. 设置帧参数frame_duration = 0.02; % 帧长20msframe_length = round(frame_duration * fs);frame_shift = round(frame_length/2); % 50%帧移% 3. 分帧操作 - 处理所有帧frames = buffer(data, frame_length, frame_length - frame_shift, &apos;nodelay&apos;);num_frames = size(frames, 2); % 获取总帧数% 4. 应用Hamming窗到所有帧hamm_win = hamming(frame_length); % 创建Hamming窗% 对每一帧应用窗函数for i = 1:num_frames frames(:, i) = frames(:, i) .* hamm_win;end% 5. 计算短时特征% 短时能量 (加窗后)short_time_energy = sum(frames.^2, 1);% 6. 创建时间轴time_signal = (0:length(data)-1)/fs; % 原始信号时间轴frame_time = ((0:num_frames-1)*frame_shift + frame_length/2)/fs; % 帧中心时间轴% 短时能量figure()plot(frame_time, short_time_energy, &apos;r&apos;, &apos;LineWidth&apos;, 1.5);title(&apos;短时能量 (Hamming窗, 帧长20ms, 帧移50%)&apos;, &apos;FontSize&apos;, 12);xlabel(&apos;时间 (s)&apos;, &apos;FontSize&apos;, 10);ylabel(&apos;能量&apos;, &apos;FontSize&apos;, 10);xlim([0 max(time_signal)]);grid on; 1短时能量曲线呈现出两个明显的高能量峰值区段，分别位于大约 0.25-0.5 秒和 0.95-1.2 秒附近，表明在这两个时间段内语音能量较强，对应着语音中的较强发音或音节。根据图中标注的语音内容为“武汉理工大学”，可以推测这两个高能量区段分别对应着“武汉”和“理工大学”这两个主要的词汇部分。 3． 语音短时幅度 （武汉理工大学语音） 12345678910% 短时幅度 (加窗后)short_time_magnitude = sum(abs(frames), 1);% 短时幅度figure()plot(frame_time, short_time_magnitude, &apos;m&apos;, &apos;LineWidth&apos;, 1.5);title(&apos;短时幅度 (Hamming窗, 帧长20ms, 帧移50%)&apos;, &apos;FontSize&apos;, 12);xlabel(&apos;时间 (s)&apos;, &apos;FontSize&apos;, 10);ylabel(&apos;幅度&apos;, &apos;FontSize&apos;, 10);xlim([0 max(time_signal)]);grid on; 1曲线中有两个主要的高幅度区段，分别位于大约 0.25-0.5 秒 和 0.95-1.2 秒，这两个区段的幅度显著高于其他部分。0-0.25 秒幅度较低，变化较为平缓，可能对应语音的起始部分或弱音。0.5-0.95 秒幅度较低且变化较小，可能对应语音中的停顿或静音段。1.2-1.4 秒幅度再次上升后逐渐下降，可能对应语音的结束部分。 4． 语音短时过零率 （武汉理工大学语音） 1234567891011121314151617% 短时过零率 (加窗后)zero_crossing_rate = zeros(1, num_frames);for i = 1:num_frames frame = frames(:, i); signs = sign(frame); % 计算符号变化次数（过零次数） cross_points = find(diff(signs) ~= 0); zero_crossing_rate(i) = length(cross_points);end% 短时过零率figure()plot(frame_time, zero_crossing_rate, &apos;g&apos;, &apos;LineWidth&apos;, 1.5);title(&apos;短时过零率 (Hamming窗, 帧长20ms, 帧移50%)&apos;, &apos;FontSize&apos;, 12);xlabel(&apos;时间 (s)&apos;, &apos;FontSize&apos;, 10);ylabel(&apos;过零次数&apos;, &apos;FontSize&apos;, 10);xlim([0 max(time_signal)]);grid on; 1曲线中有多个高峰和低谷，表明语音信号在某些时间段内过零次数较高，而在其他时间段内过零次数较低。0.2秒到0.4秒之间：过零率出现多个高峰，过零次数在60到80之间波动。这表明在这一时间段内，语音信号的过零次数较高，可能对应清音部分。1.0秒到1.2秒之间：过零率出现一个显著的高峰，过零次数超过120。这是图中过零率最高的区域，表明这一时间段内的语音信号变化非常剧烈，可能是连续的清音或语音的突变部分。 5． 语音短时自相关 （oh语音，第45帧） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162%% 短时自相关分析（第45帧）% 计算加Hamming窗后的自相关函数N = length(frame_hamm); % 帧长max_lag = N - 1; % 最大延迟% 计算自相关函数autocorr = zeros(2*max_lag+1, 1);for lag = -max_lag:max_lag n_start = max(1, 1+lag); n_end = min(N, N+lag); autocorr(lag+max_lag+1) = sum(frame_hamm(n_start:n_end) .* ... frame_hamm(n_start-lag:n_end-lag));end% 归一化自相关函数autocorr = autocorr / max(autocorr);% 提取正延迟部分（0到max_lag）positive_lags = 0:max_lag;positive_autocorr = autocorr(max_lag+1:end);% 查找基音周期（最大峰值位置，排除0延迟）[~, max_idx] = max(positive_autocorr(21:end)); % 跳过前20个样本（避免基音倍频错误）pitch_period = max_idx + 20; % 基音周期（样本数）pitch_freq = fs / pitch_period; % 基音频率（Hz）% 创建自相关图lags = -max_lag:max_lag;figure(&apos;Color&apos;,&apos;white&apos;, &apos;Position&apos;, [100, 100, 1200, 500]);% 完整自相关函数subplot(1,2,1);plot(lags, autocorr, &apos;b&apos;, &apos;LineWidth&apos;, 1.5);hold on;plot([0, 0], ylim, &apos;k--&apos;, &apos;LineWidth&apos;, 1); % 零延迟线title({[name &apos; &apos; class &apos; &apos; id] &apos;Oh语音第45帧短时自相关函数 (Hamming窗)&apos;});xlabel(&apos;延迟 (样本)&apos;);ylabel(&apos;归一化自相关值&apos;);xlim([-max_lag, max_lag]);grid on;text(0.05*max_lag, 0.9, [&apos;基音周期: &apos; num2str(pitch_period) &apos; 样本&apos;], &apos;FontSize&apos;, 10);text(0.05*max_lag, 0.8, [&apos;基音频率: &apos; num2str(round(pitch_freq)) &apos; Hz&apos;], &apos;FontSize&apos;, 10);% 局部放大图（重点显示基音周期）subplot(1,2,2);plot(positive_lags, positive_autocorr, &apos;b&apos;, &apos;LineWidth&apos;, 1.5);hold on;plot([pitch_period, pitch_period], ylim, &apos;r--&apos;, &apos;LineWidth&apos;, 1.5); % 基音周期线title(&apos;自相关函数局部放大 (0-300样本)&apos;);xlabel(&apos;延迟 (样本)&apos;);ylabel(&apos;归一化自相关值&apos;);xlim([0, 300]);grid on;text(pitch_period+5, 0.9, [&apos;基音周期: &apos; num2str(pitch_period) &apos; 样本&apos;], &apos;FontSize&apos;, 10, &apos;Color&apos;, &apos;r&apos;);% 添加公共标注annotation(&apos;textbox&apos;,... [0.3 0.001 0.4 0.05],... &apos;String&apos;,[&apos;帧长: &apos; num2str(frame_length) &apos; 样本 | 基音频率: &apos; num2str(round(pitch_freq)) &apos; Hz&apos;],... &apos;FitBoxToText&apos;,&apos;on&apos;,... &apos;EdgeColor&apos;,&apos;none&apos;,... &apos;HorizontalAlignment&apos;,&apos;center&apos;); 1在延迟为0的位置，自相关值达到最大值1，这是自相关函数的典型特征，因为信号与自身的完全重合时相关性最强。随着延迟的增加或减少，自相关值呈现出周期性的波动。在延迟约为±50样本的位置，自相关值形成了明显的峰值。右图中在延迟为0的位置，自相关值为1。随着延迟的增加，自相关值呈现出周期性的波动。在延迟约为50样本的位置，自相关值形成了一个明显的峰值，这与左图中标注的基音周期一致。 四、 编程中遇到的问题、解决方法及存在的疑问 在计算语音信号的短时能量、短时幅度、短时过零率和短时自相关等特征时，因为公式的理解不准确、计算过程中的数值精度问题或边界处理不当等原因，导致计算结果与预期不符。解决方法：仔细研读相关公式，确保对每个特征的定义和计算方法有准确的理解。例如，在计算短时过零率时，要注意符号变化的判断条件以及如何处理连续的零值等情况。在编程实现特征计算时，要注意数值精度的问题。可以采用合适的数值类型（如双精度浮点数）来存储和计算数据，以减少舍入误差等对结果的影响。对于分帧后的语音信号，在计算每帧的特征值时，要注意边界处理。例如，在计算最后一帧时，可能会出现数据不足的情况，可以通过补零或舍弃不完整的帧等方法来解决。编写代码后，可以使用一些已知结果的测试数据来验证所编写代码的正确性。例如，可以构造一个简单的正弦信号，计算其短时能量和短时自相关等特征，并与理论结果进行比较，以检查代码是否存在错误。 12声明本文档部分内容由人工智能生成，不保证准确性，仅作参考使用。 参考文章:参考链接","link":"/2025/12/19/%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%9F%AD%E6%97%B6%E6%97%B6%E5%9F%9F%E5%88%86%E6%9E%90/"},{"title":"Hadoop的安装与伪分布式测试","text":"摘要大数据技术基础第二次实验报告仅供参考 第一部分：实验预习报告（包括实验目的、意义，实验基本原理与方法，主要仪器设备及耗材，实验方案与技术路线等） 一、实验目的与意义 掌握Hadoop安装：使学习者能够理解并独立完成Hadoop在Ubuntu系统上的安装过程。 理解Hadoop配置：让学习者了解Hadoop的配置文件和参数，以及如何根据需要修改配置。 熟悉Linux操作：通过安装过程加深对Linux系统操作的熟悉度，为后续的大数据技术学习打下基础。 实践大数据处理：通过Hadoop的安装与配置，为实际的大数据处理任务做准备 二、实验基本原理 Hadoop是一个开源的大数据处理框架，它允许跨多个机器使用分布式处理大数据集。Hadoop的核心是HDFS（Hadoop Distributed File System）和MapReduce编程模型。HDFS提供了一个高度可靠的存储系统，而MapReduce则提供了一个高效的数据处理模型。本教程主要基于原生Hadoop 2，包括Hadoop 2.6.0和2.7.1等版本，通过详细步骤和适当说明，帮助用户理解Hadoop的安装和配置过程。 Hadoop架构HDFS（Hadoop Distributed File System）：Hadoop的分布式文件系统，设计用于在大规模硬件集群上存储大量数据。HDFS将文件分割成多个块（默认为128MB），并将这些块分散存储在集群的不同节点上，从而提供高吞吐量的数据处理和高可靠性的数据存储。MapReduce：Hadoop的分布式处理框架，它通过Map和Reduce两个步骤来处理大规模数据集。Map步骤负责将输入数据转换为键值对，而Reduce步骤则对这些键值对进行归并和处理，以产生最终结果。 Hadoop 2.x版本引入了YARN（Yet Another Resource Negotiator），负责集群资源管理和任务调度，提高了系统的可扩展性和灵活性。 分布式存储数据复制：HDFS通过在不同节点上复制数据块来提高数据的可靠性。默认情况下，每个数据块会有三份复制，存放在不同的节点上，以防止硬件故障导致数据丢失。高吞吐量：HDFS优化了数据的读写操作，使其适合于大规模数据集的批量处理。它通过在多个节点上并行处理数据来实现高吞吐量。 分布式计算MapReduce编程模型：MapReduce允许开发者编写可以在多个节点上并行运行的Map和Reduce函数，从而实现对大规模数据集的并行处理。大规模数据处理：MapReduce框架能够有效地处理PB级别的数据集，通过将任务分配到集群中的多个节点上，实现大规模数据的快速处理。 Java环境依赖Java运行环境：Hadoop是用Java语言编写的，因此需要Java运行环境来执行Hadoop的各个组件。环境变量配置：为了使系统能够找到Java的执行路径，需要设置JAVA_HOME环境变量，指向Java安装目录。此外，还需要将Java的bin目录添加到系统的PATH变量中，以便在任何位置都能调用Java命令。 三、主要仪器设备及耗材硬件资源 计算机或服务器：至少需要一台计算机作为Hadoop的安装和运行环境，如果是进行集群配置，则需要多台计算机。 存储设备：足够的硬盘存储空间用于安装Hadoop及其数据存储。 网络设备：网卡和网络连接设备，用于节点间的通信。 软件资源 操作系统：Ubuntu 22.04 64位作为Hadoop运行的操作系统环境。 Java开发包（JDK）：Hadoop需要Java环境来运行，因此需要安装JDK。 SSH服务：用于无密码登录和远程管理Hadoop集群。 Apache Hadoop：Hadoop的安装包，可以从Apache官网或镜像站点下载。 文本编辑器： gedit，用于编辑配置文件。 四、实验方案与技术路线 环境搭建：在Ubuntu系统上创建hadoop用户，为Hadoop安装和配置做准备。 系统更新：更新apt包管理器，确保软件包的最新状态。 依赖安装：安装SSH服务以实现无密码登录，安装Java环境作为Hadoop运行的基础。 SSH无密码登录配置：配置SSH密钥，实现本机无密码登录。 Hadoop安装：下载Hadoop安装包，解压并设置环境变量。 单机模式配置：Hadoop默认支持单机模式，无需额外配置即可运行。 伪分布式配置：修改core-site.xml和hdfs-site.xml配置文件。格式化NameNode。启动Hadoop的NameNode和DataNode守护进程。 运行Hadoop实例：在HDFS中创建用户目录。将配置文件复制到HDFS中。运行MapReduce示例程序。 YARN配置（可选）：修改mapred-site.xml和yarn-site.xml配置文件。启动YARN和历史服务器。 PATH环境变量配置：将Hadoop的可执行文件路径添加到PATH环境变量中，方便命令行操作。 第二部分：实验过程记录（包括实验原始数据记录，实验现象记录，实验过程发现的问题等） 一、实验准备阶段 环境搭建：确保使用的是Ubuntu 64位系统。创建名为hadoop的新用户，给予必要的权限。 更新系统包：执行sudo apt-get update命令更新系统包。 安装SSH服务：安装openssh-server以实现无密码登录。 安装Java环境：选择一种方式安装JDK，并配置JAVA_HOME环境变量。 下载Hadoop：从官方网站或提供的百度云盘链接下载Hadoop安装包。 解压Hadoop：将下载的Hadoop包解压到/usr/local/目录下，并重命名文件夹为hadoop。 二、Hadoop单机配置 非分布式模式运行：直接运行Hadoop附带的例子程序，体验单机模式下的MapReduce作业。 配置HDFS：修改core-site.xml和hdfs-site.xml配置文件，设置HDFS的存储路径和文件系统。 格式化NameNode：执行hdfs namenode -format命令格式化HDFS文件系统。 启动Hadoop守护进程：执行start-dfs.sh脚本启动Hadoop的NameNode和DataNode。 三、Hadoop伪分布式配置 修改配置文件：根据伪分布式的需求，修改core-site.xml和hdfs-site.xml配置文件。 启动Hadoop：再次执行start-dfs.sh脚本启动Hadoop。 运行MapReduce作业：将数据上传到HDFS，并在HDFS上运行MapReduce作业。 查看结果：使用hdfs dfs -cat命令查看MapReduce作业的输出结果。 第三部分 结果与讨论一、实验结果分析 验证Hadoop运行状态：使用jps命令查看Hadoop守护进程是否成功启动。 验证MapReduce作业：检查MapReduce作业的输出结果是否符合预期。 访问HDFS：使用Hadoop的文件系统命令在HDFS上进行文件操作，验证HDFS的功能。具体结果图片见第二部分实验过程。 二、小结、建议及体会在本次实验中，我们成功地安装并配置了Hadoop，从单机模式到伪分布式模式的转换让我们深入理解了Hadoop的架构，包括HDFS和MapReduce的工作原理，以及它们如何实现大规模数据的分布式存储和处理。实验过程中，我们学习了Linux环境下的关键操作，如用户管理、软件包更新、SSH无密码登录配置、Java环境安装和环境变量配置。此外，我们还探索了YARN资源管理器，它是Hadoop 2.x版本中负责资源管理和任务调度的重要组件。建议在实际操作之前，通过书籍、在线课程或官方文档了解Hadoop的基本概念和架构，这将有助于更好地理解安装过程中的每个步骤。尝试安装不同版本的Hadoop，以了解它们之间的差异和兼容性问题，也是一个很好的学习方式。在掌握单机和伪分布式配置后，搭建一个小型的Hadoop集群可以进一步加深对分布式计算的理解。遇到问题时，学会查看日志文件、使用搜索引擎寻找解决方案，以及参与社区讨论，这些都是宝贵的技能。在生产环境中部署Hadoop时，还需要考虑安全性问题，如Kerberos认证和数据加密等。通过次实验，我深刻体会到了大数据技术的深度。Hadoop的安装和配置涉及多个技术层面，从Linux系统管理到Java环境配置，再到Hadoop本身的架构理解。实验过程中遇到的问题，如环境变量配置错误、SSH连接问题等，提高了我的问题解决能力。我也意识到了持续学习的重要性，因为Hadoop和大数据领域不断发展，新技术和工具层出不穷。理论知识是基础，但亲自动手实践才能真正理解技术的精髓。在遇到难题时，我经常求助于在线社区和论坛，让我认识到了社区支持的力量。这次实践不仅加深了我对Hadoop的认识，也增强了我对未来技术挑战的信心。 参考文章:参考链接","link":"/2025/12/23/Hadoop%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E6%B5%8B%E8%AF%95/"},{"title":"大数据环境的安装和部署","text":"摘要大数据技术基础第一次实验报告仅供参考 第一部分：实验预习报告（包括实验目的、意义，实验基本原理与方法，主要仪器设备及耗材，实验方案与技术路线等） 一、实验目的与意义 掌握大数据技术栈：通过实验，熟悉并掌握常见的大数据处理平台和技术栈，了解其工作原理和使用方法。 理解分布式计算和存储原理：学习分布式文件系统（HDFS）的存储原理、MapReduce 和 Spark 的分布式计算模型，掌握数据在大数据环境中的流转和处理方式。 提高集群管理和资源调度能力：通过搭建管理大数据集群，掌握集群资源管理工具（YARN）的配置与调度原理，增强集群监控、优化和故障排除的能力。 培养故障处理与调试能力：在大数据环境中，学习如何排查和修复常见的部署和运行问题，提升问题解决能力。 实践大数据分析与处理流程：通过实践数据分析和处理任务，掌握如何通过 MapReduce 或 Spark 进行大规模数据计算和分析。 二、实验基本原理 虚拟机（VM，Virtual Machine）是一种软件模拟的计算机，它可以在物理硬件上运行多个操作系统，具有与实际计算机相同的功能。虚拟机通过虚拟化技术将计算机的硬件资源（如 CPU、内存、硬盘、网络接口等）分割成多个虚拟环境，允许多个操作系统并行运行。每个虚拟机在运行时都被当作独立的计算机，操作系统和应用程序可以在其中自由运行和处理任务。 虚拟化技术让用户可以在一台物理计算机（也称为宿主机）上创建多个虚拟计算机（称为虚拟机或客机），每个虚拟机都可以运行独立的操作系统和应用程序。这种技术不仅提高了硬件资源的利用率，还大大降低了硬件成本。 三、主要仪器设备及耗材 虚拟机软件： VirtualBox，一款功能强大、性能优异、简单易用的开源免费虚拟机软件，可虚拟多种操作系统，包括Windows、Mac OS X、Linux等。 实验环境： 在Windows系统上安装VirtualBox，然后在其中安装Ubuntu操作系统。 四、实验方案与技术路线 环境搭建：在Windows系统上使用VirtualBox创建Ubuntu 16.04的Linux虚拟机。 系统安装：安装Ubuntu操作系统，并进行基本配置，如网络、存储等。 核心概念学习：深入理解Linux操作系统的核心概念和命令行工具。 大数据技术准备：在Ubuntu虚拟机上安装Java环境，为后续的大数据技术如Hadoop做准备。 实践操作：通过实际操作，掌握大数据技术的原理和应用，增强技术领悟力和问题解决能力。 第二部分：实验过程记录（包括实验原始数据记录，实验现象记录，实验过程发现的问题等）由于我的电脑已经安装Ubuntu与Windows双系统，下面给出一种在Windows中使用虚拟机安装Linux系统的步骤。打开VirtualBox虚拟机官网： 点击Windows hosts按钮： 从中科大、阿里等镜像网站下载Linux系统的iso文件。 打开VirtualBox，新建系统，自定义名字和虚拟机的存放文件夹。 虚拟光盘选择ubuntu.iso文件夹。 自定义虚拟机名称和存放位置。选择虚拟光盘为下载的Ubuntu iso文件。设置内存大小至少为4096MB（4GB），处理器选择1 CPU，其他设置保持默认。进入虚拟硬盘空间选择界面，选择10GB空间。完成系统摘要界面的设置后，点击完成新建虚拟机。 点击启动虚拟机，等待系统自动打开Ubuntu安装界面。选择中文语言，并点击下载并安装Ubuntu按钮。继续后续安装步骤，直到进入时区选择界面，选择上海时区。进入用户设置界面，姓名和计算机名使用英文名以避免路径错误。系统进入自动安装界面，等待安装完成。安装完成后，验证Ubuntu系统能够正常打开终端，确保系统成功安装并可正常运行。 第三部分 结果与讨论一、实验结果分析能够正常打开终端，Ubuntu系统安装成功 二、小结、建议及体会通过这次实验，我掌握了如何在Windows操作系统中使用VirtualBox安装Ubuntu虚拟机。在安装过程中，我意识到一些看似微小的技术细节对实验的成败至关重要，例如如何合理分配虚拟机的内存，以及如何正确配置系统启动等。这些细节需要细心处理，才能确保虚拟机的正常运行。此外，这次实验让我更加了解了不同操作系统之间的协作。通过在Windows上安装Linux虚拟机，我能够直观地看到两个不同操作系统如何共同工作，这种跨平台的操作经验无论是在未来的学习还是工作中都十分有用。实验还激发了我对大数据技术的兴趣，我计划深入研究这个领域。与此同时，我也意识到，随着技术的快速发展，持续学习至关重要。而团队合作精神也是成功的关键，这不仅有助于个人成长，也对团队的协作至关重要。总的来说，这次实验不仅让我学到了新的技能，还让我对技术有了更深的理解，我期待在未来将这些经验应用到实际问题中，并为大数据技术的发展贡献自己的力量。 参考文章:参考链接","link":"/2025/12/23/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"集成学习","slug":"集成学习","link":"/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"伪分布式","slug":"伪分布式","link":"/tags/%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Hadoop","slug":"Hadoop","link":"/tags/Hadoop/"},{"name":"环境配置","slug":"环境配置","link":"/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}],"categories":[{"name":"课程报告","slug":"课程报告","link":"/categories/%E8%AF%BE%E7%A8%8B%E6%8A%A5%E5%91%8A/"},{"name":"机器学习实验","slug":"课程报告/机器学习实验","link":"/categories/%E8%AF%BE%E7%A8%8B%E6%8A%A5%E5%91%8A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E9%AA%8C/"},{"name":"语音信号处理","slug":"课程报告/语音信号处理","link":"/categories/%E8%AF%BE%E7%A8%8B%E6%8A%A5%E5%91%8A/%E8%AF%AD%E9%9F%B3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/"},{"name":"大数据技术基础","slug":"课程报告/大数据技术基础","link":"/categories/%E8%AF%BE%E7%A8%8B%E6%8A%A5%E5%91%8A/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/"}],"pages":[{"title":"","text":"微笑墙–功能开发中–","link":"/album/index.html"},{"title":"","text":"申请友链须知 原则上只和技术类博客交换，但不包括含有和色情、暴力、政治敏感的网站。 不和剽窃、侵权、无诚信的网站交换，优先和具有原创作品的网站交换。 申请请提供：站点名称、站点链接、站点描述、logo或头像（不要设置防盗链）。 排名不分先后，刷新后重排，更新信息后请留言告知。 会定期清理很久很久不更新的、不符合要求的友链，不再另行通知。 本站不存储友链图片，如果友链图片换了无法更新。图片裂了的会替换成默认图，需要更换的请留言告知。 加载中，稍等几秒...","link":"/friend/index.html"},{"title":"","text":"碎碎念 tips：github登录后按时间正序查看、可点赞加❤️、本插件地址..「+99次查看」 碎碎念加载中，请稍等... –功能开发中–","link":"/self-talking/index.html"},{"title":"","text":"个人简介 -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;个人信息：电子信息工程 本科 博客信息 本站推荐索引 时间轴记录","link":"/about/index.html"},{"title":"","text":"来而不往非礼也畅所欲言，有留必应","link":"/message/index.html"},{"title":"音乐歌单收藏","text":"温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放哟！","link":"/music/index.html"},{"title":"","text":"&nbsp;&nbsp;听听音乐 音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。更多音乐分享请查看歌单。 &nbsp;&nbsp;看看视频 ->点击以下条目开始播放视频,向下滑动查看更多","link":"/media/index.html"}]}